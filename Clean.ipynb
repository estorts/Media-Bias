{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "from warcio import ArchiveIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79600"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = pd.read_csv('Data/sept_files.csv', header=None)\n",
    "files = list(files[0])\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agree</th>\n",
       "      <th>agree_ratio</th>\n",
       "      <th>agreeance_text</th>\n",
       "      <th>allsides_page</th>\n",
       "      <th>bias</th>\n",
       "      <th>disagree</th>\n",
       "      <th>name</th>\n",
       "      <th>total_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21052</td>\n",
       "      <td>1.680530</td>\n",
       "      <td>Agrees</td>\n",
       "      <td>https://www.allsides.com/news-source/abc-news-...</td>\n",
       "      <td>left-center</td>\n",
       "      <td>12527</td>\n",
       "      <td>ABC News (Online)</td>\n",
       "      <td>33579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>Strongly Agrees</td>\n",
       "      <td>https://www.allsides.com/news-source/above-law...</td>\n",
       "      <td>left-center</td>\n",
       "      <td>28</td>\n",
       "      <td>Above The Law</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>223</td>\n",
       "      <td>1.581560</td>\n",
       "      <td>Agrees</td>\n",
       "      <td>https://www.allsides.com/news-source/abridge-n...</td>\n",
       "      <td>allsides</td>\n",
       "      <td>141</td>\n",
       "      <td>Abridge News</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>263</td>\n",
       "      <td>2.481132</td>\n",
       "      <td>Strongly Agrees</td>\n",
       "      <td>https://www.allsides.com/news-source/aj-media-...</td>\n",
       "      <td>left</td>\n",
       "      <td>106</td>\n",
       "      <td>AJ+</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4217</td>\n",
       "      <td>0.631382</td>\n",
       "      <td>Disagrees</td>\n",
       "      <td>https://www.allsides.com/news-source/al-jazeer...</td>\n",
       "      <td>left-center</td>\n",
       "      <td>6679</td>\n",
       "      <td>Al Jazeera</td>\n",
       "      <td>10896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agree  agree_ratio   agreeance_text  \\\n",
       "0  21052     1.680530           Agrees   \n",
       "1     80     2.857143  Strongly Agrees   \n",
       "2    223     1.581560           Agrees   \n",
       "3    263     2.481132  Strongly Agrees   \n",
       "4   4217     0.631382        Disagrees   \n",
       "\n",
       "                                       allsides_page         bias  disagree  \\\n",
       "0  https://www.allsides.com/news-source/abc-news-...  left-center     12527   \n",
       "1  https://www.allsides.com/news-source/above-law...  left-center        28   \n",
       "2  https://www.allsides.com/news-source/abridge-n...     allsides       141   \n",
       "3  https://www.allsides.com/news-source/aj-media-...         left       106   \n",
       "4  https://www.allsides.com/news-source/al-jazeer...  left-center      6679   \n",
       "\n",
       "                name  total_votes  \n",
       "0  ABC News (Online)        33579  \n",
       "1      Above The Law          108  \n",
       "2       Abridge News          364  \n",
       "3                AJ+          369  \n",
       "4         Al Jazeera        10896  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sides = pd.read_csv('Data/allsides.csv')\n",
    "all_sides.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_url(url):\n",
    "    return url.replace('https://www.allsides.com/news-source/', '').replace('media-bias', '').replace('-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agree</th>\n",
       "      <th>agree_ratio</th>\n",
       "      <th>agreeance_text</th>\n",
       "      <th>allsides_page</th>\n",
       "      <th>bias</th>\n",
       "      <th>disagree</th>\n",
       "      <th>name</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>url_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21052</td>\n",
       "      <td>1.680530</td>\n",
       "      <td>Agrees</td>\n",
       "      <td>https://www.allsides.com/news-source/abc-news-...</td>\n",
       "      <td>left-center</td>\n",
       "      <td>12527</td>\n",
       "      <td>ABC News (Online)</td>\n",
       "      <td>33579</td>\n",
       "      <td>abcnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>Strongly Agrees</td>\n",
       "      <td>https://www.allsides.com/news-source/above-law...</td>\n",
       "      <td>left-center</td>\n",
       "      <td>28</td>\n",
       "      <td>Above The Law</td>\n",
       "      <td>108</td>\n",
       "      <td>abovelaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>223</td>\n",
       "      <td>1.581560</td>\n",
       "      <td>Agrees</td>\n",
       "      <td>https://www.allsides.com/news-source/abridge-n...</td>\n",
       "      <td>allsides</td>\n",
       "      <td>141</td>\n",
       "      <td>Abridge News</td>\n",
       "      <td>364</td>\n",
       "      <td>abridgenews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>263</td>\n",
       "      <td>2.481132</td>\n",
       "      <td>Strongly Agrees</td>\n",
       "      <td>https://www.allsides.com/news-source/aj-media-...</td>\n",
       "      <td>left</td>\n",
       "      <td>106</td>\n",
       "      <td>AJ+</td>\n",
       "      <td>369</td>\n",
       "      <td>aj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4217</td>\n",
       "      <td>0.631382</td>\n",
       "      <td>Disagrees</td>\n",
       "      <td>https://www.allsides.com/news-source/al-jazeer...</td>\n",
       "      <td>left-center</td>\n",
       "      <td>6679</td>\n",
       "      <td>Al Jazeera</td>\n",
       "      <td>10896</td>\n",
       "      <td>aljazeera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agree  agree_ratio   agreeance_text  \\\n",
       "0  21052     1.680530           Agrees   \n",
       "1     80     2.857143  Strongly Agrees   \n",
       "2    223     1.581560           Agrees   \n",
       "3    263     2.481132  Strongly Agrees   \n",
       "4   4217     0.631382        Disagrees   \n",
       "\n",
       "                                       allsides_page         bias  disagree  \\\n",
       "0  https://www.allsides.com/news-source/abc-news-...  left-center     12527   \n",
       "1  https://www.allsides.com/news-source/above-law...  left-center        28   \n",
       "2  https://www.allsides.com/news-source/abridge-n...     allsides       141   \n",
       "3  https://www.allsides.com/news-source/aj-media-...         left       106   \n",
       "4  https://www.allsides.com/news-source/al-jazeer...  left-center      6679   \n",
       "\n",
       "                name  total_votes    url_match  \n",
       "0  ABC News (Online)        33579      abcnews  \n",
       "1      Above The Law          108     abovelaw  \n",
       "2       Abridge News          364  abridgenews  \n",
       "3                AJ+          369           aj  \n",
       "4         Al Jazeera        10896    aljazeera  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sides['url_match'] = all_sides['allsides_page'].apply(find_url)\n",
    "all_sides.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = all_sides['url_match'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "urls = []\n",
    "t = 0\n",
    "for file in files[401:500]:\n",
    "    warc_url = 'https://commoncrawl.s3.amazonaws.com/{}'.format(file)\n",
    "    wet_url = warc_url.replace('/warc/', '/wet/').replace('warc.gz', 'warc.wet.gz')\n",
    "    r = requests.get(wet_url, stream=True)\n",
    "    records = ArchiveIterator(r.raw)\n",
    "    try:\n",
    "        i=0\n",
    "        while i < 100000:\n",
    "            record = next(records)\n",
    "            for r1, r2 in record.rec_headers.headers:\n",
    "                if r1 == 'WARC-Identified-Content-Language' and 'eng' == r2:\n",
    "                    a = record.content_stream().read()\n",
    "                    for r1_1, r2_1 in record.rec_headers.headers:\n",
    "                        if r1_1 == 'WARC-Target-URI':\n",
    "                            for source in sources:\n",
    "                                if source in r2_1:\n",
    "                                    urls.append(source)\n",
    "                                    text.append(a.decode('utf-8'))\n",
    "            i += 1\n",
    "    except:\n",
    "        t += 1\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101126, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>url_match</th>\n",
       "      <th>agree</th>\n",
       "      <th>agree_ratio</th>\n",
       "      <th>agreeance_text</th>\n",
       "      <th>allsides_page</th>\n",
       "      <th>bias</th>\n",
       "      <th>disagree</th>\n",
       "      <th>name</th>\n",
       "      <th>total_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Related changes - 2006.igem.org\\nChanges relat...</td>\n",
       "      <td>mit</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>Somewhat Agrees</td>\n",
       "      <td>https://www.allsides.com/news-source/mit-media...</td>\n",
       "      <td>left</td>\n",
       "      <td>3</td>\n",
       "      <td>Mitú</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mechanical Behavior of Al-SiCnp Nanocomposite ...</td>\n",
       "      <td>aj</td>\n",
       "      <td>263</td>\n",
       "      <td>2.481132</td>\n",
       "      <td>Strongly Agrees</td>\n",
       "      <td>https://www.allsides.com/news-source/aj-media-...</td>\n",
       "      <td>left</td>\n",
       "      <td>106</td>\n",
       "      <td>AJ+</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remote Student Internship experiences at VIC d...</td>\n",
       "      <td>npr</td>\n",
       "      <td>23457</td>\n",
       "      <td>1.249374</td>\n",
       "      <td>Somewhat Agrees</td>\n",
       "      <td>https://www.allsides.com/news-source/npr-media...</td>\n",
       "      <td>center</td>\n",
       "      <td>18775</td>\n",
       "      <td>NPR Online News</td>\n",
       "      <td>42232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Partyware, An Affair To Remember\\nHome\\nShop\\n...</td>\n",
       "      <td>fair</td>\n",
       "      <td>531</td>\n",
       "      <td>1.001887</td>\n",
       "      <td>Somewhat Agrees</td>\n",
       "      <td>https://www.allsides.com/news-source/fair-medi...</td>\n",
       "      <td>left-center</td>\n",
       "      <td>530</td>\n",
       "      <td>FAIR</td>\n",
       "      <td>1061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Franchising | Agha Juice\\nHome\\nFranchising\\nL...</td>\n",
       "      <td>aj</td>\n",
       "      <td>263</td>\n",
       "      <td>2.481132</td>\n",
       "      <td>Strongly Agrees</td>\n",
       "      <td>https://www.allsides.com/news-source/aj-media-...</td>\n",
       "      <td>left</td>\n",
       "      <td>106</td>\n",
       "      <td>AJ+</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text url_match  agree  \\\n",
       "0  Related changes - 2006.igem.org\\nChanges relat...       mit      4   \n",
       "1  Mechanical Behavior of Al-SiCnp Nanocomposite ...        aj    263   \n",
       "2  Remote Student Internship experiences at VIC d...       npr  23457   \n",
       "3  Partyware, An Affair To Remember\\nHome\\nShop\\n...      fair    531   \n",
       "4  Franchising | Agha Juice\\nHome\\nFranchising\\nL...        aj    263   \n",
       "\n",
       "   agree_ratio   agreeance_text  \\\n",
       "0     1.333333  Somewhat Agrees   \n",
       "1     2.481132  Strongly Agrees   \n",
       "2     1.249374  Somewhat Agrees   \n",
       "3     1.001887  Somewhat Agrees   \n",
       "4     2.481132  Strongly Agrees   \n",
       "\n",
       "                                       allsides_page         bias  disagree  \\\n",
       "0  https://www.allsides.com/news-source/mit-media...         left         3   \n",
       "1  https://www.allsides.com/news-source/aj-media-...         left       106   \n",
       "2  https://www.allsides.com/news-source/npr-media...       center     18775   \n",
       "3  https://www.allsides.com/news-source/fair-medi...  left-center       530   \n",
       "4  https://www.allsides.com/news-source/aj-media-...         left       106   \n",
       "\n",
       "              name  total_votes  \n",
       "0             Mitú            7  \n",
       "1              AJ+          369  \n",
       "2  NPR Online News        42232  \n",
       "3             FAIR         1061  \n",
       "4              AJ+          369  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = pd.DataFrame({'text': text,\n",
    "                       'url_match': urls})\n",
    "full_data = pd.merge(text_df, all_sides, how='left', on='url_match')\n",
    "print(full_data.shape)\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.to_csv('cleaned_data_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(102222, 10)\n",
      "2\n",
      "(101796, 10)\n",
      "3\n",
      "(101553, 10)\n",
      "4\n",
      "(102690, 10)\n",
      "5\n",
      "(101126, 10)\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for i in list(range(1, 6)):\n",
    "    print(i)\n",
    "    df = pd.read_csv('cleaned_data_{}.csv'.format(i))\n",
    "    print(df.shape)\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(509387, 10)\n"
     ]
    }
   ],
   "source": [
    "dfs = pd.concat(dfs)\n",
    "print(dfs.shape)\n",
    "dfs.to_csv('full_articles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file)\n",
    "dfs = dfs[dfs['bias'] != 'allsides']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['left', 'left-center', 'center', 'right', 'right-center'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_num(target):\n",
    "    if target == 'left':\n",
    "        return 0\n",
    "    elif target == 'left-center':\n",
    "        return 1\n",
    "    elif target == 'center':\n",
    "        return 2\n",
    "    elif target == 'right':\n",
    "        return 3\n",
    "    elif target == 'right-center':\n",
    "        return 4\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['target'] = dfs['bais'].apply(convert_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.1, random_state=42)\n",
    "#create count object\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "#Transform the training data using only the 'text' column values\n",
    "X_train = count_vectorizer.fit_transform(train_data['text'])\n",
    "\n",
    "#Transform the test data using only the 'text' column values\n",
    "X_test = count_vectorizer.transform(test_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_data, tfidf_test_data = train_test_split(df, test_size=0.1, random_state=42)\n",
    "#create count object\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "#Transform the training data using only the 'text' column values\n",
    "tfidf_X_train = tfidf_vectorizer.fit_transform(tfidf_train_data['text'])\n",
    "\n",
    "#Transform the test data using only the 'text' column values\n",
    "tfidf_X_test = tfidf_vectorizer.transform(tfidf_test_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_train_data, hash_test_data = train_test_split(df, test_size=0.1, random_state=42)\n",
    "#create count object\n",
    "hash_vectorizer = HashingVectorizer(stop_words='english')\n",
    "\n",
    "#Transform the training data using only the 'text' column values\n",
    "hash_X_train = hash_vectorizer.fit_transform(hash_train_data['text'])\n",
    "\n",
    "#Transform the test data using only the 'text' column values\n",
    "hash_X_test = hash_vectorizer.transform(hash_test_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['target']\n",
    "y_test = test_data['target']\n",
    "tfidf_y_train = tfidf_train_data['target']\n",
    "tfidf_y_test = tfidf_test_data['target']\n",
    "hash_y_train = hash_train_data['target']\n",
    "hash_y_test = hash_test_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train_x, train_y, text_x, test_y, word):\n",
    "    logit = LogisticRegression(multi_class='multinomial')\n",
    "\n",
    "    logit = logit.fit(train_x, train_y)\n",
    "    \n",
    "    print('Testing Model.')\n",
    "    y_pred_logit = logit.predict(text_x)\n",
    "\n",
    "    acc = accuracy_score(test_y, y_pred_logit)\n",
    "    recall = recall_score(test_y, y_pred_logit, average='weighted')\n",
    "    perc = precision_score(test_y, y_pred_logit, average='weighted')\n",
    "    f1 = f1_score(test_y, y_pred_logit, average='weighted')\n",
    "    \n",
    "    #model results\n",
    "    print('Model Results')\n",
    "    print('Accuracy: {}'.format(acc))\n",
    "    print('Recall: {}'.format(recall))\n",
    "    print('Precision: {}'.format(perc))\n",
    "    print('F1-Score: {}'.format(f1))\n",
    "    \n",
    "    return pd.DataFrame({'Word Format': word,\n",
    "                        'Accuracy': acc,\n",
    "                        'Recall': recall,\n",
    "                        'Precision': perc,\n",
    "                        'F1-Score': f1})\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for word in ['Count', 'TFIDF', 'Hash']:\n",
    "    if word == 'Count':\n",
    "        results.append(model(X_train, y_train, X_test, y_test, word))\n",
    "    elif word == 'TFIDF':\n",
    "        results.append(model(tfidf_X_train, tfidf_y_train, tfidf_X_test, tfidf_y_test, word))\n",
    "    elif word == 'Hash':\n",
    "        results.append(model(hash_X_train, hash_y_train, hash_X_test, hash_y_test, word))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat(results)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
